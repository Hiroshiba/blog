<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hiho&#39;s Blog</title>
  
  
  <link href="/blog/atom.xml" rel="self"/>
  
  <link href="https://hiroshiba.github.io/"/>
  <updated>2017-12-03T20:31:32.294Z</updated>
  <id>https://hiroshiba.github.io/</id>
  
  <author>
    <name>Kazuyuki Hiroshiba</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>マストドンアイドル チュートリアル</title>
    <link href="https://hiroshiba.github.io/mastodon-idol-tutorial/"/>
    <id>https://hiroshiba.github.io/mastodon-idol-tutorial/</id>
    <published>2017-11-30T14:52:19.000Z</published>
    <updated>2017-12-03T20:31:32.294Z</updated>
    
    <content type="html"><![CDATA[<h3 id="なに？"><a href="#なに？" class="headerlink" title="なに？"></a>なに？</h3><p>マストドンアイドルに厳格な定義はありません。その意味は、漠然と、<a href="https://github.com/tootsuite/mastodon" target="_blank" rel="external">マストドン</a>で人気のある人を指しています。狭義には、<a href="https://friends.nico/" target="_blank" rel="external">friends.nico</a>で生放送する人のことを指します。</p><h3 id="だれが？"><a href="#だれが？" class="headerlink" title="だれが？"></a>だれが？</h3><p>創作活動をしている、あるいはしたいと思っているが、モチベーションが湧かない人向けです。</p><h3 id="なぜ？"><a href="#なぜ？" class="headerlink" title="なぜ？"></a>なぜ？</h3><p>チャット感覚での交流が行われるマストドンは、創作活動のフィードバックを得られやすいためです。</p><a id="more"></a><p>何かしらの才能を持っているけど、それを日常でいまいち発揮できないクリエイターがたくさんいます。そういう人たちはたまに、ニコ動投稿者や、Youtuberを目指します。しかし、これらはファンの獲得が難しく、最初に人気を獲得するまでに挫折してしまうことが多いです。</p><p>それらのアイドルを目指す前に、SNSで一定のファンを得ておくと、初めたばかりでもフィードバックがもらえ、やる気に繋がります。そのSNSとして、チャット感覚でユーザー間交流ができるマストドンが適しています。</p><h3 id="どこで？"><a href="#どこで？" class="headerlink" title="どこで？"></a>どこで？</h3><p>ユーザー数が多い、クリエイターが多い、同趣味の人がいる可能性が高いマストドンインスタンスだと良いです。</p><p>創作活動の内容によって最適なインスタンスは変わります。専用のインスタンスでやっても良いですが、 <em>チャット文化が根付いていてユーザー数も多い<a href="https://friends.nico/" target="_blank" rel="external">friends.nico</a></em> で始めることをおすすめします。</p><h3 id="どうやって？"><a href="#どうやって？" class="headerlink" title="どうやって？"></a>どうやって？</h3><p>まずマストドンを初めてチャットベースで知り合いを増やします。続いて創作活動の経験があればその体験を、なければ抱負を語ります。興味を示してくれた知り合いが、あなたのファンです。</p><p>マストドンでのアイドル活動の流れを、例で紹介します。</p><h4 id="自信のある創作活動がある例（歌がうまい）"><a href="#自信のある創作活動がある例（歌がうまい）" class="headerlink" title="自信のある創作活動がある例（歌がうまい）"></a>自信のある創作活動がある例（歌がうまい）</h4><ol><li>マストドンを始める</li><li>ユーザーとチャットベースで交流し、知り合いを増やす</li><li>会話の流れで出た曲を歌った録音をアップロードするなど、歌がうまいことを伝える</li><li>知り合いが興味を持つ（＝ファン）</li><li>生放送など、よりコストの掛かる創作活動をする</li></ol><p>会話の流れで出た何かを使うことで、知り合いが興味を持ってくれやすくなります。会話はチャットベースで進みます。そのため脈絡のない発言は、ほとんどの場合で興味も持たれません。</p><p>脈絡があれば興味は持たれます。誰かのアイコンを描いたり、ショートストーリーを書いたり、誰かの放送の発言をMADにしたり、マストドン用の簡単なシステムを作ったり、手法は様々です。</p><h4 id="自信のある創作活動がないが、強い興味がある例（ゲーム作りたい）"><a href="#自信のある創作活動がないが、強い興味がある例（ゲーム作りたい）" class="headerlink" title="自信のある創作活動がないが、強い興味がある例（ゲーム作りたい）"></a>自信のある創作活動がないが、強い興味がある例（ゲーム作りたい）</h4><ol><li>マストドンを始める</li><li>ユーザーとチャットベースで交流し、知り合いを増やす</li><li>会話の流れで、ゲームを作りたいことを伝える</li><li>知り合いが興味を持つ（＝ファン）</li><li>ゲーム作成の本を買うなど、よりコストの掛かる創作活動をする</li></ol><p>これも同じく、会話の流れで発言することで興味を持ってくれやすくなります。突然言っても、スルーされたり反応が少なかったりします。</p><h3 id="いつ？"><a href="#いつ？" class="headerlink" title="いつ？"></a>いつ？</h3><h4 id="まだアカウントを持っていない場合"><a href="#まだアカウントを持っていない場合" class="headerlink" title="まだアカウントを持っていない場合"></a>まだアカウントを持っていない場合</h4><p>今すぐでも良いですが、新規参入者が多いタイミングで入るとより良いです。インスタンスには独自の文化が根づいています。新参が自分ひとりだと、昔からいる人たちの輪に入りづらいためです。friends.nicoであれば、ニコニコのバージョンアップの際が最も良いでしょう。他にも、大手ITサイトがマストドン関連の記事を出した際など、イベントがあったタイミングがベストです。</p><h4 id="既にアカウントがある場合"><a href="#既にアカウントがある場合" class="headerlink" title="既にアカウントがある場合"></a>既にアカウントがある場合</h4><p>ある程度仲の良い知り合いが増えた段階だと良いです。10人程度から挨拶を貰えるようになった段階が理想です。</p><h3 id="最後に"><a href="#最後に" class="headerlink" title="最後に"></a>最後に</h3><p>マストドンにいろんなクリエイターが集まって欲しいなー、という願いがあってこんな記事を書きました。</p><p>僕自身、friends.nicoでマストドンアイドル活動（創作活動＋生放送）やってます。内容は主にプログラミングやDeeeeeeepLearningです。良ければ<a href="http://com.nicovideo.jp/community/co3686550" target="_blank" rel="external">茶化しに来て</a>ください。</p><p>この記事は、<a href="https://adventar.org/calendars/2220" target="_blank" rel="external">friends.nicoアドベントカレンダー</a>初日の投稿記事です。12月1日の0時に間に合わせる予定でした。しかし、<a href="https://twitter.com/hiho_karuta/status/936153544800976896" target="_blank" rel="external">11月30日現在はタイに出張</a>しており、記事を書き始めた22時には日本時間で12月になってしまっていました。すみませんでした。でも、間に合わせるつもりでした。許してください。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;なに？&quot;&gt;&lt;a href=&quot;#なに？&quot; class=&quot;headerlink&quot; title=&quot;なに？&quot;&gt;&lt;/a&gt;なに？&lt;/h3&gt;&lt;p&gt;マストドンアイドルに厳格な定義はありません。
その意味は、漠然と、&lt;a href=&quot;https://github.com/tootsuite/mastodon&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;マストドン&lt;/a&gt;で人気のある人を指しています。
狭義には、&lt;a href=&quot;https://friends.nico/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;friends.nico&lt;/a&gt;で生放送する人のことを指します。&lt;/p&gt;
&lt;h3 id=&quot;だれが？&quot;&gt;&lt;a href=&quot;#だれが？&quot; class=&quot;headerlink&quot; title=&quot;だれが？&quot;&gt;&lt;/a&gt;だれが？&lt;/h3&gt;&lt;p&gt;創作活動をしている、あるいはしたいと思っているが、モチベーションが湧かない人向けです。&lt;/p&gt;
&lt;h3 id=&quot;なぜ？&quot;&gt;&lt;a href=&quot;#なぜ？&quot; class=&quot;headerlink&quot; title=&quot;なぜ？&quot;&gt;&lt;/a&gt;なぜ？&lt;/h3&gt;&lt;p&gt;チャット感覚での交流が行われるマストドンは、創作活動のフィードバックを得られやすいためです。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>CBHGを使って声質変換してみる</title>
    <link href="https://hiroshiba.github.io/CBHG%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E5%A3%B0%E8%B3%AA%E5%A4%89%E6%8F%9B%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B/"/>
    <id>https://hiroshiba.github.io/CBHGを使って声質変換してみる/</id>
    <published>2017-11-16T22:28:38.000Z</published>
    <updated>2017-11-16T22:28:38.648Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>声優統計コーパスをアライメントしてみる</title>
    <link href="https://hiroshiba.github.io/sandbox-alignment-voice-actress-data/"/>
    <id>https://hiroshiba.github.io/sandbox-alignment-voice-actress-data/</id>
    <published>2017-11-03T10:58:12.000Z</published>
    <updated>2017-11-03T11:07:22.020Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h3><ul><li>（背景）声質変換用のデータを作るために音声アライメントを試してみたい</li><li>（手法）<a href="http://voice-statistics.github.io/" target="_blank" rel="external">声優統計コーパス</a>のデータを使用し、MFCCでアライメントした</li><li>（結果）アライメント後の音声はところどころ伸びていた。無音とする閾値を下げると伸びは抑制された。</li><li>（考察）もっと完璧に揃うと思っていた。</li></ul><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/muteup-aligned-melspec-1-000.svg" alt="muteup-aligned-melspec-1-000.svg" title="">  <figcaption>話者１のメルスペクトログラム</figcaption></figure><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/muteup-aligned-melspec-2-000.svg" alt="muteup-aligned-melspec-2-000.svg" title="">  <figcaption>話者２のメルスペクトログラム</figcaption></figure><a id="more"></a><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>DeeeeepLearingを使って声質変換してみたい。どうやら最初に、違う話者による同じ発話内容の音声を揃える必要があるらしい。声質変換用のデータを作るために音声アライメントを試してみた。</p><h3 id="手法"><a href="#手法" class="headerlink" title="手法"></a>手法</h3><p>データセットは<a href="http://voice-statistics.github.io/" target="_blank" rel="external">声優統計コーパス</a>の音声データを使用した。話者は<code>fujitou_normal</code>（話者１）と<code>tsuchiya_normal</code>（話者２）を選んだ。</p><p>アライメント用の特徴量はいろんな文献に従いMFCCとした。MFCC抽出には<a href="http://ml.cs.yamanashi.ac.jp/world/" target="_blank" rel="external">World</a>と、そのpythonラッパー<a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder" target="_blank" rel="external">pyworld</a>を用いた。</p><p>音声のアライメントはMFCCにDTWを適用した結果を用いた。DTWは<a href="https://r9y9.github.io/nnmnkwii/latest/nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html" target="_blank" rel="external">音声変換の実装例</a>アライメントされた音声の生成は、DTW結果のindexに従ってSTFTを並び替え、STFTを逆変換して求めた。</p><p>比較用にメルスペクトログラムを求め、作図に用いた。これの生成は<a href="https://github.com/keithito/tacotron/blob/master/util/audio.py" target="_blank" rel="external">tacotronの実装例</a>を参考にした。</p><p>コードは<a href="https://gist.github.com/Hiroshiba/25fee12b3e51b2209b249fdfbb6ade88" target="_blank" rel="external">gist</a>に公開した。無音とする閾値は<code>librosa.effects.split</code>の<code>top_db</code>で変更できる。</p><h3 id="結果"><a href="#結果" class="headerlink" title="結果"></a>結果</h3><h4 id="アライメントされた音声"><a href="#アライメントされた音声" class="headerlink" title="アライメントされた音声"></a>アライメントされた音声</h4><p>話者１と話者２の音声をアライメント結果は以下のようになった。</p><figure>  <audio src="raw-voice-1-000.wav" controls></audio>  <figcaption>話者１の元ボイス</figcaption></figure><figure>  <audio src="raw-voice-2-000.wav" controls></audio>  <figcaption>話者２の元ボイス</figcaption></figure><figure>  <audio src="aligned-voice-1-000.wav" controls></audio>  <figcaption>アライメントされた話者１のボイス</figcaption></figure><figure>  <audio src="raw-voice-2-000.wav" controls></audio>  <figcaption>アライメントされた話者２のボイス</figcaption></figure><p>前半はきれいに揃っているが、後半の最後は伸びた感じになっていた。</p><h4 id="アライメントされたメルスペクトログラム"><a href="#アライメントされたメルスペクトログラム" class="headerlink" title="アライメントされたメルスペクトログラム"></a>アライメントされたメルスペクトログラム</h4><p>先程の音声のメルスペクトログラムは以下のようになった。</p><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/raw-melspec-1-000.svg" alt="raw-melspec-1-000.svg" title="">  <figcaption>話者１の元ボイスのメルスペクトログラム</figcaption></figure><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/raw-melspec-2-000.svg" alt="raw-melspec-2-000.svg" title="">  <figcaption>話者２の元ボイスのメルスペクトログラム</figcaption></figure><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/aligned-melspec-1-000.svg" alt="aligned-melspec-1-000.svg" title="">  <figcaption>アライメントされた話者１の元ボイスのメルスペクトログラム</figcaption></figure><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/aligned-melspec-2-000.svg" alt="aligned-melspec-2-000.svg" title="">  <figcaption>アライメントされた話者２の元ボイスのメルスペクトログラム</figcaption></figure><p>無音区間の部分アライメントに悪影響しているようだった。</p><h4 id="無音区間の閾値を下げてアライメントした結果"><a href="#無音区間の閾値を下げてアライメントした結果" class="headerlink" title="無音区間の閾値を下げてアライメントした結果"></a>無音区間の閾値を下げてアライメントした結果</h4><p>無音区間とする音圧の閾値を下げてアライメントした。<code>librosa.effects.split</code>の<code>top_db</code>をデフォルト値から<code>20</code>にした。</p><figure>  <audio src="muteup-aligned-voice-1-000.wav" controls></audio>  <figcaption>話者１のボイス</figcaption></figure><figure>  <audio src="muteup-aligned-voice-2-000.wav" controls></audio>  <figcaption>話者２のボイス</figcaption></figure><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/muteup-aligned-melspec-1-000.svg" alt="muteup-aligned-melspec-1-000.svg" title="">  <figcaption>話者１のメルスペクトログラム</figcaption></figure><figure>  <img src="/blog/sandbox-alignment-voice-actress-data/muteup-aligned-melspec-2-000.svg" alt="muteup-aligned-melspec-2-000.svg" title="">  <figcaption>話者２のメルスペクトログラム</figcaption></figure><p>ところどころブザーのような音になった。よくなっているように思える。</p><h3 id="考察"><a href="#考察" class="headerlink" title="考察"></a>考察</h3><p>DTWの仕組みから考えて無音区間は点的なのだろう。積極的に排除した方がいい。（声質変換の論文の実験データ項目を見ても、MFCCを使った、程度のことしか書いてなかった。）</p><p>DTWで音声が完璧に揃えられると思っていたけど、いまいちだった。とりあえずこのまま機械学習の入出力にしたいと思う。</p><p>MFCCでDTWして別のデータを並び替えるために、DTWAlignerに別のデータを与える設計にしたが、これは良くない。<a href="https://librosa.github.io/librosa/generated/librosa.effects.trim.html#" target="_blank" rel="external">librosa.effects.trim</a>のように、インデックスを返す実装の方がいい。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;目次&quot;&gt;&lt;a href=&quot;#目次&quot; class=&quot;headerlink&quot; title=&quot;目次&quot;&gt;&lt;/a&gt;目次&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;（背景）声質変換用のデータを作るために音声アライメントを試してみたい&lt;/li&gt;
&lt;li&gt;（手法）&lt;a href=&quot;http://voice-statistics.github.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;声優統計コーパス&lt;/a&gt;のデータを使用し、MFCCでアライメントした&lt;/li&gt;
&lt;li&gt;（結果）アライメント後の音声はところどころ伸びていた。無音とする閾値を下げると伸びは抑制された。&lt;/li&gt;
&lt;li&gt;（考察）もっと完璧に揃うと思っていた。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure&gt;
  &lt;img src=&quot;/blog/sandbox-alignment-voice-actress-data/muteup-aligned-melspec-1-000.svg&quot; alt=&quot;muteup-aligned-melspec-1-000.svg&quot; title=&quot;&quot;&gt;
  &lt;figcaption&gt;話者１のメルスペクトログラム&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;figure&gt;
  &lt;img src=&quot;/blog/sandbox-alignment-voice-actress-data/muteup-aligned-melspec-2-000.svg&quot; alt=&quot;muteup-aligned-melspec-2-000.svg&quot; title=&quot;&quot;&gt;
  &lt;figcaption&gt;話者２のメルスペクトログラム&lt;/figcaption&gt;
&lt;/figure&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ブログ作りました</title>
    <link href="https://hiroshiba.github.io/first-commit/"/>
    <id>https://hiroshiba.github.io/first-commit/</id>
    <published>2017-09-30T20:12:35.000Z</published>
    <updated>2017-11-02T12:21:42.028Z</updated>
    
    <content type="html"><![CDATA[<p>技術系の日記をつける予定です。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;技術系の日記をつける予定です。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
