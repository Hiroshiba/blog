<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title>声優統計コーパスをアライメントしてみる | Hiho's Blog</title><meta name="description" content="声優統計コーパスをアライメントしてみる - Kazuyuki Hiroshiba"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/blog/images/favicon.png"><link rel="stylesheet" href="/blog/css/theme.css"><link rel="search" type="application/opensearchdescription+xml" href="/blog/atom.xml" title="Hiho's Blog"></head><body><div class="wrap"><header><h1 class="branding"><a href="/blog/" title="Hiho's Blog">Hiho's Blog</a></h1><ul class="nav nav-list"><li class="nav-list-item"><a class="nav-list-link" href="/blog/archives" target="_self">ARCHIVES</a></li><li class="nav-list-item"><a class="nav-list-link" href="https://github.com/Hiroshiba" target="_blank">GITHUB</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">声優統計コーパスをアライメントしてみる</h1><div class="post-info"><a></a>2017-11-03</div><div class="post-content"><h3 id="目次"><a href="#目次" class="headerlink" title="目次"></a>目次</h3><ul>
<li>（背景）声質変換用のデータを作るために音声アライメントを試してみたい</li>
<li>（手法）<a href="http://voice-statistics.github.io/" target="_blank" rel="external">声優統計コーパス</a>のデータを使用し、MFCCでアライメントした</li>
<li>（結果）アライメント後の音声はところどころ伸びていた。無音とする閾値を下げると伸びは抑制された。</li>
<li>（考察）もっと完璧に揃うと思っていた。</li>
</ul>
<figure>
  <img src="muteup-aligned-melspec-1-000.svg" alt="">
  <figcaption>話者１のメルスペクトログラム</figcaption>
</figure>

<figure>
  <img src="muteup-aligned-melspec-2-000.svg" alt="">
  <figcaption>話者２のメルスペクトログラム</figcaption>
</figure>

<a id="more"></a>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>DeeeeepLearingを使って声質変換してみたい。
どうやら最初に、違う話者による同じ発話内容の音声を揃える必要があるらしい。
声質変換用のデータを作るために音声アライメントを試してみた。</p>
<h3 id="手法"><a href="#手法" class="headerlink" title="手法"></a>手法</h3><p>データセットは<a href="http://voice-statistics.github.io/" target="_blank" rel="external">声優統計コーパス</a>の音声データを使用した。
話者は<code>fujitou_normal</code>（話者１）と<code>tsuchiya_normal</code>（話者２）を選んだ。</p>
<p>アライメント用の特徴量はいろんな文献に従いMFCCとした。
MFCC抽出には<a href="http://ml.cs.yamanashi.ac.jp/world/" target="_blank" rel="external">World</a>と、そのpythonラッパー<a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder" target="_blank" rel="external">pyworld</a>を用いた。</p>
<p>音声のアライメントはMFCCにDTWを適用した結果を用いた。
DTWは<a href="https://r9y9.github.io/nnmnkwii/latest/nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html" target="_blank" rel="external">音声変換の実装例</a>アライメントされた音声の生成は、DTW結果のindexに従ってSTFTを並び替え、STFTを逆変換して求めた。</p>
<p>比較用にメルスペクトログラムを求め、作図に用いた。
これの生成は<a href="https://github.com/keithito/tacotron/blob/master/util/audio.py" target="_blank" rel="external">tacotronの実装例</a>を参考にした。</p>
<p>コードは<a href="https://gist.github.com/Hiroshiba/25fee12b3e51b2209b249fdfbb6ade88" target="_blank" rel="external">gist</a>に公開した。
無音とする閾値は<code>librosa.effects.split</code>の<code>top_db</code>で変更できる。</p>
<h3 id="結果"><a href="#結果" class="headerlink" title="結果"></a>結果</h3><h4 id="アライメントされた音声"><a href="#アライメントされた音声" class="headerlink" title="アライメントされた音声"></a>アライメントされた音声</h4><p>話者１と話者２の音声をアライメント結果は以下のようになった。</p>
<figure>
  <audio src="raw-voice-1-000.wav" controls></audio>
  <figcaption>話者１の元ボイス</figcaption>
</figure>

<figure>
  <audio src="raw-voice-2-000.wav" controls></audio>
  <figcaption>話者２の元ボイス</figcaption>
</figure>

<figure>
  <audio src="aligned-voice-1-000.wav" controls></audio>
  <figcaption>アライメントされた話者１のボイス</figcaption>
</figure>

<figure>
  <audio src="raw-voice-2-000.wav" controls></audio>
  <figcaption>アライメントされた話者２のボイス</figcaption>
</figure>

<p>前半はきれいに揃っているが、後半の最後は伸びた感じになっていた。</p>
<h4 id="アライメントされたメルスペクトログラム"><a href="#アライメントされたメルスペクトログラム" class="headerlink" title="アライメントされたメルスペクトログラム"></a>アライメントされたメルスペクトログラム</h4><p>先程の音声のメルスペクトログラムは以下のようになった。</p>
<figure>
  <img src="raw-melspec-1-000.svg" alt="">
  <figcaption>話者１の元ボイスのメルスペクトログラム</figcaption>
</figure>

<figure>
  <img src="raw-melspec-2-000.svg" alt="">
  <figcaption>話者２の元ボイスのメルスペクトログラム</figcaption>
</figure>

<figure>
  <img src="aligned-melspec-1-000.svg" alt="">
  <figcaption>アライメントされた話者１の元ボイスのメルスペクトログラム</figcaption>
</figure>

<figure>
  <img src="aligned-melspec-2-000.svg" alt="">
  <figcaption>アライメントされた話者２の元ボイスのメルスペクトログラム</figcaption>
</figure>

<p>無音区間の部分アライメントに悪影響しているようだった。</p>
<h4 id="無音区間の閾値を下げてアライメントした結果"><a href="#無音区間の閾値を下げてアライメントした結果" class="headerlink" title="無音区間の閾値を下げてアライメントした結果"></a>無音区間の閾値を下げてアライメントした結果</h4><p>無音区間とする音圧の閾値を下げてアライメントした。
<code>librosa.effects.split</code>の<code>top_db</code>をデフォルト値から<code>20</code>にした。</p>
<figure>
  <audio src="muteup-aligned-voice-1-000.wav" controls></audio>
  <figcaption>話者１のボイス</figcaption>
</figure>

<figure>
  <audio src="muteup-aligned-voice-2-000.wav" controls></audio>
  <figcaption>話者２のボイス</figcaption>
</figure>

<figure>
  <img src="muteup-aligned-melspec-1-000.svg" alt="">
  <figcaption>話者１のメルスペクトログラム</figcaption>
</figure>

<figure>
  <img src="muteup-aligned-melspec-2-000.svg" alt="">
  <figcaption>話者２のメルスペクトログラム</figcaption>
</figure>

<p>ところどころブザーのような音になった。よくなっているように思える。</p>
<h3 id="考察"><a href="#考察" class="headerlink" title="考察"></a>考察</h3><p>DTWの仕組みから考えて無音区間は点的なのだろう。積極的に排除した方がいい。
（声質変換の論文の実験データ項目を見ても、MFCCを使った、程度のことしか書いてなかった。）</p>
<p>DTWで音声が完璧に揃えられると思っていたけど、いまいちだった。
とりあえずこのまま機械学習の入出力にしたいと思う。</p>
<p>MFCCでDTWして別のデータを並び替えるために、DTWAlignerに別のデータを与える設計にしたが、これは良くない。
<a href="https://librosa.github.io/librosa/generated/librosa.effects.trim.html#" target="_blank" rel="external">librosa.effects.trim</a>のように、インデックスを返す実装の方がいい。</p>
</div></article></div></main><footer><div class="paginator"><a class="next" href="/blog/first-commit/">next</a></div><div class="copyright"><p>&copy; 2017 <a href="https://hiroshiba.github.io/blog">Hiroshiba</a>.<br>Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/Dreyer/hexo-theme-artemis" target="_blank">Artemis</a>.</p></div></footer></div></body></html>