---
title: 「ディープラーニングの力で結月ゆかりの声になってみた」の試行錯誤
tags:
categories:
permalink:
description:
---

試行錯誤を語る

<!-- more -->

### パラメータ

### その他試行錯誤

似たようなことやってる人は多いはず。
本実験に当たっての試行錯誤を報告する。

#### 音響特徴量の変換

低音質な音響特徴量の変換は最終的にpix2pixモデルを用いたが、その他にいろいろ試していた。
まずTacotronでも使われていたCBHGモデル（CNN++LSTM）を適用してみたが、LSTMが強すぎて過学習してしまった（前回のブログ参考）。
LSTMをなくすと、過学習は多少ましになったが今度は誤差が大きすぎて使い物にならなかった。

まあこういうときはGANでしょと思って１次元多層CNNの判別器を使ってみたが、これがどうにも上手くいかない。
確かに滑舌は多少ましになる（子音が表現されるようになる）が、CNNの大きさに従って音声が振動するような感じになった。
画像分野でもCNN+GANを行うと周期的な模様が出ることがあったので、それと似たような現象だと思われる。

最終的に1次元pix2pixになったが、これだとそこそこ上手く行った理由はよくわからない。
それでも子音は無視されがちになり、滑舌がよろしくない結果になってしまった。
データ数が少ないことも原因の１つだと考えられるので、データ数を増やせば多少性能が上がると踏んでいる。
GANベースで音響特徴量を推定するのは無茶だ。早く引き返せ。
