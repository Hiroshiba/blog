---
title: リアルタイム声質変換のOSS化
tags:
categories:
permalink: realtime-yukarin-introduction
description:
---

### はじめに
リアルタイム声質変換アプリケーション、[Realtime Yukarin](https://github.com/Hiroshiba/realtime-yukarin)を開発し、OSSとして公開しました。
ここで言う声質変換とは、「誰でも好きな声になれる」技術のことを指します。
好きな声になれる声質変換は夢があって流行りそうなのですが、まだ全然普及していないと思います。
それは現時点で、声質変換を実際にリアルタイムで使えるフリーな仕組みが無いためだと考えました。
そこで、自由に使えるリアルタイム声質変換アプリケーションを作り、ソースコードと合わせて公開しました。

<!-- more -->

### 声質変換とは

声を変える方法で有名なのは、声の高さや音色を変える手法、いわゆるボイスチェンジャーです。
既存のボイスチェンジャーは、元の声を起点として、変換パラメータを自分で調整する必要があります。
一方ここでの声質変換は、元の声と好きな声を用いて機械学習し、変換パラメータを自動で調整します。

<figure>
  <figcaption>既存のボイスチェンジャーと声質変換の違い</figcaption>
  <img src="7.svg" style="max-height: 14em">
</figure>

また、声質変換は、ボイスチェンジャーで変換できないパラメータも変換することができます。
音声は、声の高さ・声の音色・イントネーション・音の強弱などに分解できますが、
ボイスチェンジャーが変換するのは声の高さと音色だけです。
声質変換は、イントネーションや音の強弱も変換することができます。

### Realtime Yukarinとは
#### 何ができるか
声質変換の機械学習タスクで作成したモデルと、GPU搭載パソコンを用いて、
コマンド１つでリアルタイムな声質変換ができます。
また、OSSなので、これをベースにコードを改良したり、
商用非商用問わずアプリケーションに組み込んだりすることができます。

#### どうやってできるか
声質変換を担当する[Yukarin](https://github.com/Hiroshiba/yukarin)モデルと、
変換結果を高品質化する[Become Yukarin](https://github.com/Hiroshiba/become-yukarin)モデルの、
２つの機械学習済みモデルを用意する必要があります。
それぞれのリンク先のドキュメントに従って、誰でも機械学習済みモデルを作成することができます。

#### どう動いているか
音声入力デバイスから取り込んだ音声を細切れ（セグメント化と呼ぶことにします）にしたあと、
セグメントごとに変換し、繋ぎ合わせてから音声に戻します。

<figure>
  <img src="1.svg" style="max-height: 7.5em">
</figure>

### 特徴
#### 変換処理を３段階に分け、それぞれを別プロセスで動かす
変換処理を１プロセスで行う場合、セグメントの長さよりも変換に時間がかかると、変換結果の音声が途切れてしまいます。

<figure>
  <img src="2.svg" style="max-height: 10.5em">
</figure>

Realtime Yukarinでは、変換処理をエンコード、コンバート、デコードの３段階に分け、
それぞれ別プロセスで処理するように工夫しており、スムーズに変換処理を行います。

<figure>
  <img src="3.svg" style="max-height: 14.5em">
</figure>

#### セグメントをオーバーラップさせて変換精度を一定にする
Realtime Yukarinは、声質変換の際に前後の入力音声も用いることで、変換精度を向上させています。
しかし、セグメント端は音声が欠けているため、その区間だけ変換精度が下がってしまいます。

<figure>
  <img src="4.svg" style="max-height: 9.5em">
</figure>

これを避けるために、Realtime Yukarinでは、セグメントをオーバーラップできる機能を用意し、変換精度を一定に保ちます。

<figure>
  <img src="5.svg" style="max-height: 9.5em">
</figure>

#### ノイズを除去する

全ての音を声に変換する声質変換では、小さなノイズを拾って声を生成しようとし、
大きなノイズが出力されてしまうことがあります。
Realtime Yukarinでは、音量ベースの簡単なノイズ除去機能を用意し、耳障りなノイズを減らす工夫をしています。

### デモ
Intel Core i7-7700 CPU @ 3.60GHzと、GeForce GTX 1060 6GBを搭載したWindowsパソコンを使って、
遅延約1.5秒の声質変換が可能です。

デモ

### おわりに
最初に声質変換を使ってみてから１年間かけ、自分自身で検証を重ねてクオリティと実用性を上げました。
そしてやっと、誰でもリアルタイム声質変換を使える仕組み、Realtime Yukarinを公開することができました。
これで、ちょっとでも声質変換が普及したら嬉しいです。ぜひお試しください。

* [ソースコード（GitHub)](https://github.com/Hiroshiba/realtime-yukarin)

また、今年の５月に、Realtime Yukarinを用いて、声質変換した声でお客さんと会話するイベントを行いました。
Realtime Yukarinは、実際の現場でもちゃんと使えると思います。

* [声質変換を用いたイベント例](https://blog.hiroshiba.jp/backstage-of-talking-event-with-yuzuki-yukari/)

私の次のチャレンジは、声質変換をより普及させることです。
声質変換の機械学習をより簡単に行える仕組みを作ったり、誰でも声質変換を試せるサービスを作ったりを考えています。
しかし、簡単化するためには開発のための時間と知識が、サービス化のためには計算資源が必要になります。
クラウドファンディングにて資金を募っておりますので、もし期待してくださるのであれば、助力頂けるととても嬉しいです。

* クラウドファンディングの宣伝
